[
    {
        "title": "Intrinsic Credit Assignment for Long Horizon Interaction",
        "authors": [
            "Ilze Amanda Auzina*",
            "Joschka Strüber*",
            "Sergio Hernández-Gutiérrez*",
            "Shashwat Goel",
            "Ameya Prabhu",
            "Matthias Bethge"
        ],
        "venue": "",
        "year": "2026",
        "status": "unpublished",
        "type": "TBA",
        "abstract": "How can we train agents to navigate uncertainty over long horizons? In this work, we propose ΔBelief-RL, which leverages a language model's own intrinsic beliefs to reward intermediate progress. Our method utilizes the change in the probability an agent assigns to the target solution for credit assignment. By training on synthetic interaction data, ΔBelief-RL teaches information-seeking capabilities that consistently outperform purely outcome-based rewards for RL, with improvements generalizing to out-of-distribution applications ranging from customer service to personalization. Notably, the performance continues to improve as we scale test-time interactions beyond the training horizon, with interaction-efficiency increasing even on Pass@k metrics. Overall, our work introduces a scalable training strategy for navigating uncertainty over a long-horizon, by enabling credit assignment to intermediate actions via intrinsic ΔBelief rewards.",
        "links": [
            {
                "title": "Website",
                "url": "https://bethgelab.github.io/delta-belief-rl/",
                "icon": "mdi:web"
            },
            {
                "title": "AlphaXiv",
                "url": "https://www.alphaxiv.org/abs/intrinsic-credit-assignment",
                "icon": "academicons:arxiv"
            },
            {
                "title": "GitHub",
                "url": "https://github.com/bethgelab/delta-belief-rl/",
                "icon": "mdi:github"
            }
        ]
    },
    {
        "title": "Co-Adaptation of Embodiment and Control with Self-Imitation Learning",
        "authors": ["Sergio Hernández-Gutiérrez", "Ville Kyrki", "Kevin S. Luck"],
        "venue": "IROS",
        "year": "2025",
        "status": "published",
        "type": "conference",
        "abstract": "The task of co-optimizing the body and behaviour of agents has been a long-standing problem in the fields of evolutionary robotics and embodied AI. Previous work has largely focused on the development of learning methods exploiting massive parallelization of agent evaluations with large population sizes, a paradigm which is applicable to simulated agents but cannot be transferred to the real world due to the associated costs with the production of embodiments and robots. Furthermore, recent data-efficient approaches utilizing reinforcement learning can suffer from distributional shifts in transition dynamics as well as in state and action spaces when experiencing new body morphologies. In this work, we propose a new co-adaptation method combining reinforcement learning and State-Aligned Self-Imitation Learning to co-design embodiment and behavioural policies within a handful of design iterations. We show that the integration of a self-imitation signal improves the data-efficiency of the co-adaptation process as well as the behavioural recovery when adapting morphological parameters.",
        "links": [
            {
                "title": "PDF",
                "url": "https://drive.google.com/file/d/1uQEYDniZz1ubMvXdcEXgogzOZylDJo06/view?usp=sharing",
                "icon": "tabler:file-type-pdf"
            },
            {
                "title": "GitHub",
                "url": "https://github.com/serhez/cosil",
                "icon": "mdi:github"
            }
        ]
    },

    {
        "title": "Recursive Decomposition with Dependencies for Generic Divide and Conquer Reasoning",
        "authors": ["Sergio Hernández-Gutiérrez", "Minttu Alakuijala", "Alexander V. Nikitin", "Pekka Marttinen"],
        "venue": "NeurIPS Sys2 Reasoning",
        "year": "2024",
        "status": "published",
        "type": "workshop",
        "abstract": "Reasoning tasks are crucial in many domains, especially in science and engineering. Although large language models (LLMs) have made progress in reasoning tasks using techniques such as chain-of-thought and least-to-most prompting, these approaches still do not effectively scale to complex problems in either their performance or execution time. Moreover, they often require additional supervision for each new task, such as in-context examples. In this work, we introduce Recursive Decomposition with Dependencies (RDD), a scalable divide-and-conquer method for solving reasoning problems that requires less supervision than prior approaches. Our method can be directly applied to a new problem class even in the absence of any task-specific guidance. Furthermore, RDD supports sub-task dependencies, allowing for ordered execution of sub-tasks, as well as an error recovery mechanism that can correct mistakes made in previous steps. We evaluate our approach on two benchmarks with six difficulty levels each and in two in-context settings: one with task-specific examples and one without. Our results demonstrate that RDD outperforms other methods in a compute-matched setting as task complexity increases, while also being more computationally efficient.",
        "recognitions": "",
        "links": [
            {
                "title": "ArXiv",
                "url": "https://arxiv.org/abs/2505.02576",
                "icon": "academicons:arxiv"
            },
            {
                "title": "GitHub",
                "url": "https://github.com/serhez/lmethods",
                "icon": "mdi:github"
            }
        ]
    },

    {
        "title": "Following Ancestral Footsteps: Co-Designing Morphology and Behaviour with Self-Imitation Learning",
        "authors": ["Sergio Hernández-Gutiérrez", "Ville Kyrki", "Kevin S. Luck"],
        "venue": "EARL RSS (oral presentation) and EWRL",
        "year": "2024",
        "status": "published",
        "type": "workshop",
        "abstract": "In this paper we consider the problem of co-adapting the body and behaviour of agents, a long-standing research problem in the community of evolutionary robotics. Previous work has largely focused on the development of methods exploiting massive parallelization of agent evaluations with large population sizes, a paradigm which is not applicable to the real world. More recent data-efficient approaches utilizing reinforcement learning can suffer from distributional shifts in transition dynamics as well as in state and action spaces when experiencing new body morphologies. In this work, we propose a new co-adaptation method combining reinforcement learning and State-Aligned Self-Imitation Learning. We show that the integration of a self-imitation signal improves the data-efficiency of the co-adaptation process as well as the behavioural recovery when adapting morphological parameters.",
        "recognitions": "Best Workshop Paper Award (EARL RSS)",
        "links": [
            {
                "title": "PDF",
                "url": "https://openreview.net/forum?id=lHlhqoWfjw",
                "icon": "tabler:file-type-pdf"
            },
            {
                "title": "GitHub",
                "url": "https://github.com/serhez/cosil",
                "icon": "mdi:github"
            }
        ]
    },
    {
        "title": "Solving Reasoning Problems with Large Language Models via Recursive Decomposition",
        "authors": ["Sergio Hernández-Gutiérrez", "Pekka Marttinen", "Alexander Nikitin", "Minttu Alakuijala"],
        "venue": "Aalto University",
        "year": "2024",
        "status": "published",
        "type": "thesis",
        "abstract": "This thesis studies the recursive decomposition of reasoning problems with large language models. We propose two methods implementing this technique: one enforcing sub-problem independence during the decomposition of problems and the other enabling the modeling of dependencies between sub-problems. We evaluate these methods on two benchmarks with six difficulty levels each and on two in-context settings with contrasting degrees of task-specific data availability. We find that our methods employing recursive decomposition outperform state-of-the-art baselines as the complexity of the tasks increases while being more time and space-efficient. We additionally provide an analysis of the errors the methods made during our experiments; they also can recover from mistakes made during the problem-solving process. The formulation of our methodology enables its integration into generic intelligent systems safe parallelization of a great part of its execution, as well as its composition with other state-of-the-art frameworks. We open-source our implementation of these methods, along with a wider set of tools to augment the software landscape for reasoning research with large language models.",
        "recognitions": "",
        "links": [
            {
                "title": "PDF",
                "url": "https://drive.google.com/file/d/1-7M4VIyXvbIWQL9-pllrtX1UrDSnccgM/view?usp=share_link",
                "icon": "tabler:file-type-pdf"
            }
        ]
    },

    {
        "title": "A Comprehensive Overview of Goal-Conditioned Hierarchical Reinforcement Learning: Algorithms, Challenges, and Future Directions",
        "authors": ["Sergio Hernández-Gutiérrez", "Vivienne Wang"],
        "venue": "Aalto University",
        "year": "2023",
        "status": "unpublished",
        "type": "seminar",
        "abstract": "Hierarchical reinforcement learning (HRL) methods have recently enabled higher sample efficiency in high-dimensional and long reinforcement learning (RL) problems. Goal-conditioned HRL (GCHRL) approaches concretize these hierarchical ideas by providing reachable sub-goals and considering a chain of policies that model the actions required to reach them, which are either less abstract sub-goals or the agent's native actions. This paper analyses and compares the current state-of-the-art GCHRL methods. Additionally, it discusses the current and future key challenges of the area, including efficient state space exploration, meaningful sub-goal generation and representation, the non-stationarity of policies and the transfer of skills learnt for one problem to solve another. Finally, it contributes to the current discussion on future directions and key focus points within the field of GCHRL.",
        "recognitions": "",
        "links": [
            {
                "title": "PDF",
                "url": "https://drive.google.com/file/d/1YSmY4q4-I3WdhUrqD_MyJmcspv-ckyLm/view?usp=share_link",
                "icon": "tabler:file-type-pdf"
            }
        ]
    },

    {
        "title": "Modal Logic Theorem Provers and Validity Rates",
        "authors": ["Sergio Hernández-Gutiérrez", "Robin Hirsch"],
        "venue": "University College London",
        "year": "2019",
        "status": "published",
        "type": "thesis",
        "abstract": "During my Bachelor's thesis at UCL, supervised by Prof. Robin Hirsch, I carried out a study on the validity rates of modal logic formulae as their complexity increases (i.e., more allowed connectives and larger formulae). For this purpose, I implemented a frame-based analytical tableau theorem prover for propositional modal logics K, KT, KB, K4, KD and linear modal logic. This implementation was compared to Molle, a state-of-the-art theorem prover for modal logics at the time; this analysis found inconsistencies in the results of both provers, concluding with evidence of Molle's incorrectness on complex formulae.",
        "recognitions": "",
        "links": [
            {
                "title": "PDF",
                "url": "https://drive.google.com/file/d/1EUqOJb5ZK0bOM0Ix1LSmzKXcPGj2d8Pa/view?usp=sharing",
                "icon": "tabler:file-type-pdf"
            }
        ]
    },

    {
        "title": "3D Reconstruction of Fire-Damaged Parchments",
        "authors": ["Sergio Hernández-Gutiérrez", "Wanyue Zhang", "Ionut Deocanu"],
        "venue": "Microsoft Faculty Connection",
        "year": "2018",
        "status": "published",
        "type": "article",
        "abstract": "In this article in partnership with Microsoft, as a Microsoft Student Partner, I give an introduction to 3D reconstruction of physical objects. In particular, I explain the process of reconstructing fire-damaged parchments and, as part of my 2nd year project at UCL, building a product for archivists and other professionals who are in need of a parchment-reconstruction tool to read them.",
        "recognitions": "",
        "links": [
            {
                "title": "Microsoft Faculty Connection",
                "url": "https://learn.microsoft.com/en-us/archive/blogs/uk_faculty_connection/3d-reconstruction-of-fire-damage-parchments",
                "icon": "mdi-microsoft"
            }
        ]
    }
]
